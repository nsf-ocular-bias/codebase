{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import effnetv2_model\n",
    "\n",
    "MODEL = 'efficientnetv2-b3'\n",
    "ckpt_path = r\"F:\\Lab\\nfs\\nsl\\training-run-b3-adam\\ckpt-269\"\n",
    "# Build model\n",
    "tf.keras.backend.clear_session()\n",
    "model = effnetv2_model.EffNetV2Model(model_name=MODEL)\n",
    "\n",
    "model.compile('rmsprop', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "_ = model(tf.ones([1, 224, 224, 3]), training=False)\n",
    "model.load_weights(ckpt_path)\n",
    "cfg = model.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.base_optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.base_optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale.current_loss_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale.current_loss_scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale.good_steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.loss_scale.good_steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 312ms/step - loss: 0.7997 - accuracy: 0.9459\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 306ms/step - loss: 1.4892 - accuracy: 0.9017\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 350ms/step - loss: 0.6301 - accuracy: 0.9599\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 337ms/step - loss: 1.8478 - accuracy: 0.8775\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 315ms/step - loss: 0.6834 - accuracy: 0.9559\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 332ms/step - loss: 1.4755 - accuracy: 0.9048\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 342ms/step - loss: 0.8427 - accuracy: 0.9442\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 315ms/step - loss: 1.7711 - accuracy: 0.8853\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 322ms/step - loss: 0.6079 - accuracy: 0.9587\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 356ms/step - loss: 3.7751 - accuracy: 0.7503\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 353ms/step - loss: 0.3331 - accuracy: 0.9788\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 360ms/step - loss: 1.8131 - accuracy: 0.8781\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 326ms/step - loss: 0.2174 - accuracy: 0.9828\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 264ms/step - loss: 1.4716 - accuracy: 0.8965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run inference for a given image\n",
    "import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = preprocessing.preprocess_image(\n",
    "        img, cfg.eval.isize, is_training=False, augname=cfg.data.augname)\n",
    "    return img\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"F:\\Lab\\datasets\\fairface\\fairface_label_val.csv\")\n",
    "\n",
    "df.file = df.file.apply(lambda x: os.path.join(\n",
    "    r\"F:\\Lab\\datasets\\fairface\\fairface-img-margin025-trainval\", x))\n",
    "\n",
    "races = df.race.unique()\n",
    "genders = df.gender.unique()\n",
    "history = []\n",
    "for race in races:\n",
    "    for gender in genders:\n",
    "        df_filtered = df[df.gender == gender]\n",
    "        df_filtered = df_filtered[df_filtered.race == race]\n",
    "        label = int(gender == \"Male\")\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(list(df_filtered.file))\n",
    "        test_ds = test_ds.map(lambda x: preprocess(\n",
    "            x), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        labels_ds = tf.data.Dataset.from_tensor_slices(\n",
    "            len(df_filtered) * [label])\n",
    "        test_ds = tf.data.Dataset.zip((test_ds, labels_ds))\n",
    "        test_ds = test_ds.batch(128)\n",
    "        hist = model.evaluate(test_ds)\n",
    "        history.append([race, gender, hist])\n",
    "\n",
    "\n",
    "# logits = model(tf.expand_dims(image, 0), False)\n",
    "\n",
    "# # Output classes and probability\n",
    "# pred = tf.keras.layers.Softmax()(logits)\n",
    "# idx = tf.argsort(logits[0])[::-1][:5].numpy()\n",
    "# import ast\n",
    "# classes = ast.literal_eval(open(labels_map, \"r\").read())\n",
    "# for i, id in enumerate(idx):\n",
    "#   print(f'top {i+1} ({pred[0][id]*100:.1f}%):  {classes[id]} ')\n",
    "# from IPython import display\n",
    "# display.display(display.Image(image_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['East Asian', 'Male', [0.8966054320335388, 0.9395109415054321]],\n",
       " ['East Asian', 'Female', [1.5804468393325806, 0.8926261067390442]],\n",
       " ['White', 'Male', [0.9198470115661621, 0.9385026693344116]],\n",
       " ['White', 'Female', [1.6984361410140991, 0.8878504633903503]],\n",
       " ['Latino_Hispanic', 'Male', [0.7877232432365417, 0.9432534575462341]],\n",
       " ['Latino_Hispanic', 'Female', [1.4217491149902344, 0.9048192501068115]],\n",
       " ['Southeast Asian', 'Male', [0.8697397112846375, 0.9442176818847656]],\n",
       " ['Southeast Asian', 'Female', [2.1105213165283203, 0.8514705896377563]],\n",
       " ['Black', 'Male', [0.823609471321106, 0.9424280524253845]],\n",
       " ['Black', 'Female', [4.123591423034668, 0.7199471592903137]],\n",
       " ['Indian', 'Male', [0.4614535868167877, 0.9681274890899658]],\n",
       " ['Indian', 'Female', [2.041430711746216, 0.8623853325843811]],\n",
       " ['Middle Eastern', 'Male', [0.5231021642684937, 0.9643296599388123]],\n",
       " ['Middle Eastern', 'Female', [1.024112343788147, 0.9217171669006348]]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30030c8eb72a285f14a9b9a9bb0f2d503ef7c8bbe57528465e9b07c96938a01f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
